{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82777535-ee38-48ab-9a9f-faa5fa0e84d0",
   "metadata": {},
   "source": [
    "# Intel® oneAPI Hackathon for Open Innovation - Accelerating PyTorch Deep Learning Models on Intel XPUs - Hands-on Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ff0d5-9a01-448d-a47b-9187caf78207",
   "metadata": {},
   "source": [
    "## Use of Intel® Extension for PyTorch* for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83d67a-3578-495f-a1ae-a5da6436c598",
   "metadata": {},
   "source": [
    "In this hands-on lab we will demonstrate how **IPEX** can be used for **resnet50** model training in PyTorch framework. For any other PyTorch model, same process can be followed to leverage IPEX optimizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e570290-a906-43d8-8e04-738f8f02c30f",
   "metadata": {},
   "source": [
    "### Computer Vision Workload - Transfer learning with Resnet50 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597dacf8-6a70-405e-8b51-220c100286a9",
   "metadata": {},
   "source": [
    "In this notebook image classification is done using transfer learning with resnet50 model. ResNet-50 is a convolutional neural network that is 50 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database. In this notebook all architecture except the last layer is fixed. The last layer is modified for two classes. With very less epoch very good accuracy can be achieved. The network has an image input size of 224-by-224.\n",
    "We are going to use the **optimize** method from Intel® Extension for PyTorch* to apply optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197362a4-4f23-4bd9-bbb4-414b5dad5a0c",
   "metadata": {},
   "source": [
    "Refer to https://intel.github.io/intel-extension-for-pytorch/latest/tutorials/installation.html for installation guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f554d4-ba83-4fa7-ab5b-d509512d6db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          24\n",
      "On-line CPU(s) list:             0-23\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              6\n",
      "Socket(s):                       2\n",
      "NUMA node(s):                    2\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           85\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6128 CPU @ 3.40GHz\n",
      "Stepping:                        4\n",
      "CPU MHz:                         1200.191\n",
      "CPU max MHz:                     3700.0000\n",
      "CPU min MHz:                     1200.0000\n",
      "BogoMIPS:                        6800.00\n",
      "Virtualization:                  VT-x\n",
      "L1d cache:                       384 KiB\n",
      "L1i cache:                       384 KiB\n",
      "L2 cache:                        12 MiB\n",
      "L3 cache:                        38.5 MiB\n",
      "NUMA node0 CPU(s):               0-5,12-17\n",
      "NUMA node1 CPU(s):               6-11,18-23\n",
      "Vulnerability Itlb multihit:     KVM: Vulnerable\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT vulnerable\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled v\n",
      "                                 ia prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Full generic retpoline, IBPB condit\n",
      "                                 ional, IBRS_FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Mitigation; Clear CPU buffers; SMT vulnerable\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush dts acpi mmx f\n",
      "                                 xsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rd\n",
      "                                 tscp lm constant_tsc art arch_perfmon pebs bts \n",
      "                                 rep_good nopl xtopology nonstop_tsc cpuid aperf\n",
      "                                 mperf pni pclmulqdq dtes64 monitor ds_cpl vmx s\n",
      "                                 mx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid d\n",
      "                                 ca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadli\n",
      "                                 ne_timer aes xsave avx f16c rdrand lahf_lm abm \n",
      "                                 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 inv\n",
      "                                 pcid_single pti intel_ppin ssbd mba ibrs ibpb s\n",
      "                                 tibp tpr_shadow vnmi flexpriority ept vpid ept_\n",
      "                                 ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 \n",
      "                                 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq\n",
      "                                  rdseed adx smap clflushopt clwb intel_pt avx51\n",
      "                                 2cd avx512bw avx512vl xsaveopt xsavec xgetbv1 x\n",
      "                                 saves cqm_llc cqm_occup_llc cqm_mbm_total cqm_m\n",
      "                                 bm_local dtherm ida arat pln pts hwp hwp_act_wi\n",
      "                                 ndow hwp_epp hwp_pkg_req pku ospke md_clear flu\n",
      "                                 sh_l1d arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!lscpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85360602-b707-4bcd-ac8f-36524c131476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /home/u154865/.local/lib/python3.9/site-packages (1.12.1+cpu)\n",
      "Requirement already satisfied: torchvision in /home/u154865/.local/lib/python3.9/site-packages (0.13.1+cpu)\n",
      "Requirement already satisfied: torchaudio in /home/u154865/.local/lib/python3.9/site-packages (0.12.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/u154865/.local/lib/python3.9/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/u154865/.local/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: numpy in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->torchvision) (4.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: intel_extension_for_pytorch in /home/u154865/.local/lib/python3.9/site-packages (1.12.300)\n",
      "Requirement already satisfied: psutil in /glob/development-tools/versions/oneapi/2022.3.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_pytorch) (5.9.4)\n"
     ]
    }
   ],
   "source": [
    "#Installation steps \n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!python -m pip install intel_extension_for_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301f9cd7-9b88-42e7-ab04-5e2cae5d24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "zf = ZipFile('./HE_Workshop/Pytorch/training_set.zip', 'r')\n",
    "zf.extractall('training_data')\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e36054-b70b-45d1-a319-4885fcdebf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "zf = ZipFile('./HE_Workshop/Pytorch/test_set.zip', 'r')\n",
    "zf.extractall('test_data')\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae572201-b070-4a4e-a092-e6faa7aa0574",
   "metadata": {},
   "source": [
    "Let's start by importing all the necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501534f9-4e20-4634-9d27-5e207e1939a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import time\n",
    "input_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55a8782-cd2b-4aea-8e59-8348149bc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': \n",
    "    datasets.ImageFolder(input_path + 'training_data/training_set', data_transforms['train']),\n",
    "    'validation': \n",
    "    datasets.ImageFolder(input_path + 'test_data/test_set', data_transforms['validation'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0),  # for Kaggle\n",
    "    'validation':\n",
    "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size=32,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0)  # for Kaggle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e739556c-8812-45c0-af39-120bbb1f1736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u154865/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/u154865/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "    \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "    \n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c034e64-a665-4aac-b9dc-d81fca9ae04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7673ee0-c230-45e2-866f-13d8f3b67efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    since= time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                       epoch_acc))\n",
    "    time_elapsed = time.time() - since\n",
    "    train_model.ttime= time_elapsed\n",
    "    print('Training completed in {:.0f}m {:.0f}s \\n \\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b0b68-8681-4b57-a225-1b575844f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.12.1+cpu\n",
      "ipex version：   1.12.300\n",
      "Training with normal PyTorch\n",
      "Epoch 1/3\n",
      "----------\n",
      "train loss: 0.1321, acc: 0.9445\n",
      "Epoch 2/3\n",
      "----------\n",
      "train loss: 0.0904, acc: 0.9645\n",
      "Epoch 3/3\n",
      "----------\n",
      "train loss: 0.0852, acc: 0.9680\n",
      "Training completed in 27m 25s \n",
      " \n",
      "\n",
      "Training with Intel Extension for PyTorch (IPEX)\n",
      "Epoch 1/3\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"pytorch version: {}\".format(torch.__version__))\n",
    "print(\"ipex version：   {}\".format(ipex.__version__))\n",
    "print(\"Training with normal PyTorch\")\n",
    "model_trained = train_model(model, criterion, optimizer, num_epochs=3)\n",
    "dur_n = train_model.ttime\n",
    "print(\"Training with Intel Extension for PyTorch (IPEX)\")\n",
    "model, optimizer = ipex.optimize(model, optimizer=optimizer)\n",
    "model_trained = train_model(model, criterion, optimizer, num_epochs=3)\n",
    "dur_i = train_model.ttime\n",
    "print('Training time (normal): {:.2f}sec'.format(dur_n))\n",
    "print('Training time (ipex):   {:.2f}sec'.format(dur_i))\n",
    "print('IPEX achieved {:.2f}% better performance comparing to normal PyTorch, Speed up of {:.2f}x'.format((dur_n-dur_i)/dur_n*100, dur_n/dur_i))\n",
    "\n",
    "plt.bar([\"normal\", \"ipex\"], [dur_n, dur_i], width=0.5 , color = ['red' , 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064c143-fbdb-4fb9-b749-2c979e03217e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
